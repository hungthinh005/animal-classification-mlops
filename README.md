# Animal Classification MLOps

A production-ready MLOps project for multiclass animal image classification using Convolutional Neural Networks (CNNs) and Transfer Learning with ResNet-50.

## ğŸ¯ Project Overview

This project demonstrates a complete ML lifecycle implementation for classifying animal images across multiple species. It includes data preprocessing, model training with multiple architectures, evaluation, and deployment via REST API.

### Key Features

- **Multiple Model Architectures**: Custom CNNs and ResNet-50 with transfer learning
- **MLflow Integration**: Experiment tracking and model registry
- **FastAPI Deployment**: REST API for real-time predictions
- **Comprehensive Testing**: Unit tests for all components
- **Docker Support**: Containerized deployment
- **CI/CD Pipeline**: Automated testing and deployment

## ğŸ“ Project Structure

```
animal-classification-mlops/
â”œâ”€â”€ api/                      # FastAPI application
â”‚   â”œâ”€â”€ main.py              # API endpoints
â”‚   â””â”€â”€ test_client.py       # API test client
â”œâ”€â”€ configs/                  # Configuration files
â”‚   â””â”€â”€ config.yaml          # Main configuration
â”œâ”€â”€ data/                     # Data directory
â”‚   â”œâ”€â”€ raw/                 # Raw data
â”‚   â”œâ”€â”€ processed/           # Processed data
â”‚   â””â”€â”€ predictions/         # Prediction outputs
â”œâ”€â”€ models/                   # Saved models
â”œâ”€â”€ notebooks/                # Jupyter notebooks
â”œâ”€â”€ src/                      # Source code
â”‚   â”œâ”€â”€ data/                # Data processing
â”‚   â”‚   â”œâ”€â”€ dataset.py
â”‚   â”‚   â””â”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ models/              # Model architectures
â”‚   â”‚   â”œâ”€â”€ cnn_models.py
â”‚   â”‚   â”œâ”€â”€ resnet_model.py
â”‚   â”‚   â””â”€â”€ model_factory.py
â”‚   â”œâ”€â”€ training/            # Training modules
â”‚   â”‚   â”œâ”€â”€ trainer.py
â”‚   â”‚   â””â”€â”€ early_stopping.py
â”‚   â”œâ”€â”€ evaluation/          # Evaluation modules
â”‚   â”‚   â”œâ”€â”€ evaluator.py
â”‚   â”‚   â””â”€â”€ predictor.py
â”‚   â””â”€â”€ utils/               # Utilities
â”‚       â”œâ”€â”€ config.py
â”‚       â”œâ”€â”€ logger.py
â”‚       â””â”€â”€ metrics.py
â”œâ”€â”€ tests/                    # Test suite
â”œâ”€â”€ logs/                     # Training logs
â”œâ”€â”€ outputs/                  # Output artifacts
â”œâ”€â”€ Dockerfile               # Docker configuration
â”œâ”€â”€ docker-compose.yml       # Docker Compose configuration
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ pyproject.toml           # Project metadata
â””â”€â”€ README.md                # This file
```

## ğŸš€ Getting Started

### Prerequisites

- Python 3.9+
- CUDA-capable GPU (optional, for faster training)
- Docker (optional, for containerized deployment)

### Installation

1. **Clone the repository**

```bash
git clone https://github.com/yourusername/animal-classification-mlops.git
cd animal-classification-mlops
```

2. **Create virtual environment**

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**

```bash
pip install -r requirements.txt
```

### Quick Start

#### 1. Data Preparation

Download and prepare the dataset:

```python
from src.data.preprocessing import download_kaggle_dataset, prepare_data

# Download dataset
download_kaggle_dataset(
    "iamsouravbanerjee/animal-image-dataset-90-different-animals",
    "data/raw"
)

# Split into train/test
prepare_data(
    source_dir="data/raw/animals/animals",
    target_dir="data/processed",
    test_ratio=0.2,
    num_classes=10
)
```

#### 2. Train Model

```python
from src.utils.config import load_config
from src.data.dataset import AnimalDataset, get_transforms, get_dataloaders
from src.models.model_factory import create_model
from src.training.trainer import Trainer

# Load configuration
config = load_config("configs/config.yaml")

# Create datasets
transform = get_transforms(config, is_training=True)
train_dataset = AnimalDataset("data/processed/train", transform=transform, num_classes=10)

# Create model
model = create_model(config)

# Train
trainer = Trainer(model, config, device="cuda")
history = trainer.train(train_loader, val_loader, epochs=50)
```

Or use the training script:

```bash
python scripts/train.py --config configs/config.yaml
```

#### 3. Evaluate Model

```python
from src.evaluation.evaluator import Evaluator

evaluator = Evaluator(model, device="cuda", class_names=class_names)
metrics = evaluator.evaluate(test_loader)
print(metrics)
```

#### 4. Run API Server

```bash
cd api
uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```

Test the API:

```bash
python api/test_client.py path/to/image.jpg
```

## ğŸ—ï¸ Model Architectures

### 1. CNNDualConv (VGG-style)
- Multiple convolutional blocks with batch normalization
- Dropout for regularization
- Suitable for smaller datasets

### 2. CNNSingleConv
- Lightweight architecture
- Faster training
- Lower parameter count

### 3. ResNet-50 (Transfer Learning)
- Pretrained on ImageNet
- Fine-tuned for animal classification
- Best performance on the benchmark

## ğŸ“Š Experiment Tracking

This project uses MLflow for experiment tracking:

```bash
# Start MLflow UI
mlflow ui --backend-store-uri mlruns

# Access at http://localhost:5000
```

## ğŸ³ Docker Deployment

### Build and Run

```bash
# Build image
docker build -t animal-classification:latest .

# Run container
docker run -p 8000:8000 animal-classification:latest
```

### Using Docker Compose

```bash
docker-compose up -d
```

## ğŸ§ª Testing

Run the test suite:

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=src --cov-report=html

# Run specific test file
pytest tests/test_models.py
```

## ğŸ“ˆ Performance

| Model | Accuracy | F1-Score | Parameters | Training Time |
|-------|----------|----------|------------|---------------|
| CNNDualConv | 65% | 0.63 | 2.5M | 20 min |
| CNNSingleConv | 45% | 0.42 | 1.2M | 10 min |
| ResNet-50 | 98% | 0.97 | 23.5M | 15 min |

*Tested on 10-class animal classification with 480 training images*

## ğŸ“ Configuration

Edit `configs/config.yaml` to customize:

- Model architecture
- Training hyperparameters
- Data augmentation settings
- API configuration
- MLflow settings

## ğŸ”„ CI/CD Pipeline

This project includes GitHub Actions workflows for:

- Automated testing on push/PR
- Code quality checks (black, flake8)
- Docker image building
- Model deployment

## ğŸ“š API Documentation

### Endpoints

- `GET /` - API information
- `GET /health` - Health check
- `POST /predict` - Predict single image
- `POST /predict/batch` - Predict multiple images
- `GET /classes` - Get supported classes

### Example Request

```python
import requests

url = "http://localhost:8000/predict"
files = {"file": open("cat.jpg", "rb")}
response = requests.post(url, files=files)
print(response.json())
```

### Example Response

```json
{
  "predicted_class": "cat",
  "confidence": 0.95,
  "top_predictions": [
    {"class": "cat", "confidence": 0.95},
    {"class": "dog", "confidence": 0.03},
    {"class": "bear", "confidence": 0.01}
  ]
}
```

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Dataset: [Animal Image Dataset](https://www.kaggle.com/datasets/iamsouravbanerjee/animal-image-dataset-90-different-animals)
- PyTorch team for the deep learning framework
- FastAPI for the modern web framework
- MLflow for experiment tracking

## ğŸ“§ Contact

For questions or feedback, please open an issue on GitHub.

---

**Built with â¤ï¸ for MLOps excellence**

